
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"我现在UIUC blender lab读计算机博士。我的导师是季姮，Heng Ji. 我的科研方向主要是信息抽取和它的应用。我在元学习，迁移学习，持续学习，弱监督学习和多模态学习方面也有一些经验。\n声明：中文页面比较写意，严肃版本请看英文。Disclaimer: Chinese page is just for fun, for serious information please go to the English version.\n","date":1708128000,"expirydate":-62135596800,"kind":"term","lang":"zh","lastmod":1708128000,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"我现在UIUC blender lab读计算机博士。我的导师是季姮，Heng Ji. 我的科研方向主要是信息抽取和它的应用。我在元学习，迁移学习，持续学习，弱监督学习和多模态学习方面也有一些经验。\n声明：中文页面比较写意，严肃版本请看英文。Disclaimer: Chinese page is just for fun, for serious information please go to the English version.","tags":null,"title":"于鹏飞","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://perfec-yu.github.io/zh/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/zh/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["于鹏飞","Jiateng Liu, Pengfei Yu,","Yuji Zhang","Sha Li","Zixuan Zhang","Heng Ji"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example. Add the publication’s full text or supplementary notes here. You can use rich formatting such as including code, math, and images.\n","date":1708128000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1708128000,"objectID":"66591d6df141a468f01074265ecdc155","permalink":"https://perfec-yu.github.io/zh/publication/liu-etal-2024-evedit/","publishdate":"2024-02-17T00:00:00Z","relpermalink":"/zh/publication/liu-etal-2024-evedit/","section":"publication","summary":"The dynamic nature of real-world information necessitates efficient knowledge editing (KE) in large language models (LLMs) for knowledge updating. However, current KE approaches, which typically operate on (subject, relation, object) triples, ignore the contextual information and the relation among different knowledge. Such editing methods could thus encounter an uncertain editing boundary, leaving a lot of relevant knowledge in ambiguity-- Queries that could be answered pre-edit cannot be reliably answered afterward. In this work, we analyze this issue by introducing a theoretical framework for KE that highlights an overlooked set of knowledge that remains unchanged and aids in knowledge deduction during editing, which we name as the deduction anchor. We further address this issue by proposing a novel task of event-based knowledge editing that pairs facts with event descriptions. This task manifests not only a closer simulation of real-world editing scenarios but also a more logically sound setting, implicitly defining the deduction anchor to address the issue of indeterminate editing boundaries. We empirically demonstrate the superiority of event-based editing over the existing setting on resolving uncertainty in edited models, and curate a new benchmark dataset EvEdit derived from the CounterFact dataset. Moreover, while we observe that the event-based setting is significantly challenging for existing approaches, we propose a novel approach Self-Edit that showcases stronger performance, achieving 55.6% consistency improvement while maintaining the naturalness of generation.","tags":["Source Themes"],"title":"EVEDIT: Event-based Knowledge Editing with Deductive Editing Boundaries","type":"publication"},{"authors":["于鹏飞","Heng Ji"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example. Add the publication’s full text or supplementary notes here. You can use rich formatting such as including code, math, and images.\n","date":1685318400,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1685318400,"objectID":"5af0824c5ba95294cc78e302ac232d29","permalink":"https://perfec-yu.github.io/zh/publication/yu-etal-2023-information/","publishdate":"2023-05-29T00:00:00Z","relpermalink":"/zh/publication/yu-etal-2023-information/","section":"publication","summary":"Language modeling doesn't imply information modeling","tags":["Source Themes"],"title":"Information Association for Language Model Updating by Mitigating LM-Logical Discrepancy","type":"publication"},{"authors":["于鹏飞","Zixuan Zhang","Clare Voss","Jonathan May","Heng Ji"],"categories":null,"content":"","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1656633600,"objectID":"3d89774d919c16ace6b79dc80a4f160f","permalink":"https://perfec-yu.github.io/zh/publication/yu-etal-2022-event/","publishdate":"2022-06-25T20:43:20.041226Z","relpermalink":"/zh/publication/yu-etal-2022-event/","section":"publication","summary":"","tags":null,"title":"Event Extractor with Only a Few Examples","type":"publication"},{"authors":["Xinya Du","Zixuan Zhang","Sha Li","于鹏飞","Hongwei Wang","Tuan Manh","Xudong Lin","Ziqi Wang","Iris Liu","Ben Zhou","Haoyang Wen","Manling Li","Darryl Hannan","Qi Zeng","Qing Lyu","Charles Yu","Carl Edwards","Xiaomeng Jin","Yizhu Jiao","Ghazaleh Kazeminejad","Rotem Dror","Zhenhailong Wang","Chris Callison-Burch","Mohit Bansal","Carl Vondrick","Jiawei Han","Dan Roth","Shih-Fu Chang","Martha Palmer","Heng Ji"],"categories":null,"content":"","date":1656633600,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1656633600,"objectID":"b5cd5af43a60aaa8de259aa3e4eaff35","permalink":"https://perfec-yu.github.io/zh/publication/du-etal-2022-resin/","publishdate":"2022-06-25T20:43:20.042461Z","relpermalink":"/zh/publication/du-etal-2022-resin/","section":"publication","summary":"","tags":null,"title":"RESIN-11: Schema-guided Event Prediction for 11 Newsworthy Scenarios","type":"publication"},{"authors":["Manling Li","Revanth Gangi Reddy","Ziqi Wang","Yi-shyuan Chiang","Tuan Lai","于鹏飞","Zixuan Zhang","Heng Ji"],"categories":null,"content":"","date":1651363200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1651363200,"objectID":"fe60d84adb5c84109cda7c7a2d97a8a7","permalink":"https://perfec-yu.github.io/zh/publication/li-etal-2022-covid/","publishdate":"2022-06-25T20:43:20.043176Z","relpermalink":"/zh/publication/li-etal-2022-covid/","section":"publication","summary":"To tackle the challenge of accurate and timely communication regarding the COVID-19 pandemic, we present a COVID-19 Claim Radar to automatically extract supporting and refuting claims on a daily basis. We provide a comprehensive structured view of claims, including rich claim attributes (such as claimers and claimer affiliations) and associated knowledge elements as claim semantics (such as events, relations and entities), enabling users to explore equivalent, refuting, or supporting claims with structural evidence, such as shared claimers, similar centroid events and arguments. In order to consolidate claim structures at the corpus-level, we leverage Wikidata as the hub to merge coreferential knowledge elements. The system automatically provides users a comprehensive exposure to COVID-19 related claims, their importance, and their interconnections. The system is publicly available at GitHub and DockerHub, with complete documentation.","tags":null,"title":"COVID-19 Claim Radar: A Structured Claim Extraction and Tracking System","type":"publication"},{"authors":["于鹏飞","Heng Ji","Prem Natarajan"],"categories":null,"content":"","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1635724800,"objectID":"f2c54e1633764b9a72306aa1cf5d88f8","permalink":"https://perfec-yu.github.io/zh/publication/yu-etal-2021-lifelong/","publishdate":"2022-06-25T20:43:20.043856Z","relpermalink":"/zh/publication/yu-etal-2021-lifelong/","section":"publication","summary":"Traditional supervised Information Extraction (IE) methods can extract structured knowledge elements from unstructured data, but it is limited to a pre-defined target ontology. In reality, the ontology of interest may change over time, adding emergent new types or more fine-grained subtypes. We propose a new lifelong learning framework to address this challenge. We focus on lifelong event detection as an exemplar case and propose a new problem formulation that is also generalizable to other IE tasks. In event detection and more general IE tasks, rich correlations or semantic relatedness exist among hierarchical knowledge element types. In our proposed framework, knowledge is being transferred between learned old event types and new event types. Specifically, we update old knowledge with new event types′ mentions using a self-training loss. In addition, we aggregate old event types′ representations based on their similarities with new event types to initialize the new event types′ representations. Experimental results show that our framework outperforms competitive baselines with a 5.1% absolute gain in the F1 score. Moreover, our proposed framework can boost the F1 score for over 30% absolute gain on some new long-tail rare event types with few training instances. Our knowledge transfer module improves performance on both learned event types and new event types under the lifelong learning setting, showing that it helps consolidate old knowledge and improve novel knowledge acquisition.","tags":null,"title":"Lifelong Event Detection with Knowledge Transfer","type":"publication"},{"authors":["Xiaodan Hu","于鹏飞","Kevin Knight","Heng Ji","Bo Li","Honghui Shi"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1609459200,"objectID":"c2f0fce9c3de5813638ba4d7e1d7a572","permalink":"https://perfec-yu.github.io/zh/publication/xiaodan-2021-muse/","publishdate":"2022-06-25T20:43:20.044556Z","relpermalink":"/zh/publication/xiaodan-2021-muse/","section":"publication","summary":"","tags":null,"title":"MUSE: Textual Attributes Guided Portrait Painting Generation","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://perfec-yu.github.io/zh/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/zh/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Xu Han","Hao Zhu","于鹏飞","Ziyun Wang","Yuan Yao","Zhiyuan Liu","Maosong Sun"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538352000,"objectID":"83dd5e9587c1af50cf495437dbbae9ea","permalink":"https://perfec-yu.github.io/zh/publication/han-etal-2018-fewrel/","publishdate":"2022-06-25T20:43:20.045135Z","relpermalink":"/zh/publication/han-etal-2018-fewrel/","section":"publication","summary":"We present a Few-Shot Relation Classification Dataset (dataset), consisting of 70, 000 sentences on 100 relations derived from Wikipedia and annotated by crowdworkers. The relation of each sentence is first recognized by distant supervision methods, and then filtered by crowdworkers. We adapt the most recent state-of-the-art few-shot learning methods for relation classification and conduct thorough evaluation of these methods. Empirical results show that even the most competitive few-shot learning models struggle on this task, especially as compared with humans. We also show that a range of different reasoning skills are needed to solve our task. These results indicate that few-shot relation classification remains an open problem and still requires further research. Our detailed analysis points multiple directions for future research.","tags":null,"title":"FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation","type":"publication"},{"authors":["Xu Han","于鹏飞","Zhiyuan Liu","Maosong Sun","Peng Li"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1538352000,"objectID":"5dec288ac7b6a412a6d795603aaadf35","permalink":"https://perfec-yu.github.io/zh/publication/han-etal-2018-hierarchical/","publishdate":"2022-06-25T20:43:20.045908Z","relpermalink":"/zh/publication/han-etal-2018-hierarchical/","section":"publication","summary":"Distantly supervised relation extraction employs existing knowledge graphs to automatically collect training data. While distant supervision is effective to scale relation extraction up to large-scale corpora, it inevitably suffers from the wrong labeling problem. Many efforts have been devoted to identifying valid instances from noisy data. However, most existing methods handle each relation in isolation, regardless of rich semantic correlations located in relation hierarchies. In this paper, we aim to incorporate the hierarchical information of relations for distantly supervised relation extraction and propose a novel hierarchical attention scheme. The multiple layers of our hierarchical attention scheme provide coarse-to-fine granularity to better identify valid instances, which is especially effective for extracting those long-tail relations. The experimental results on a large-scale benchmark dataset demonstrate that our models are capable of modeling the hierarchical information of relations and significantly outperform other baselines. The source code of this paper can be obtained from r̆lhttps://github.com/thunlp/HNRE.","tags":null,"title":"Hierarchical Relation Extraction with Coarse-to-Fine Grained Attention","type":"publication"},{"authors":["Yinpei Dai","Zhijian Ou","Dawei Ren","于鹏飞"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1514764800,"objectID":"c5d5ed7eac96896b9f682360be5fdc59","permalink":"https://perfec-yu.github.io/zh/publication/dai-2018-tracking/","publishdate":"2022-06-25T20:43:20.046658Z","relpermalink":"/zh/publication/dai-2018-tracking/","section":"publication","summary":"","tags":null,"title":"Tracking of Enriched Dialog States for Flexible Conversational Information Access","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://perfec-yu.github.io/zh/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/zh/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"}]